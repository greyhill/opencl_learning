\documentclass{article}
\usepackage{minted}
\usepackage{fullpage}
\usepackage{url}
\usepackage{hyperref}
\usepackage{fourier}
\title{OpenCL Notes}
\author{Madison McGaffin}
\begin{document}

\maketitle

\tableofcontents

\section{Installation}
On (Ubuntu) Linux, OpenCL can be gotten from a few places:
\begin{enumerate}
  \item For computers with supported nVidia graphics cards, the default
    binary nVidia drivers support OpenCL and CUDA.  The package 
    nvidia-current-dev will install the headers and libraries for
    writing OpenCL code.  Tell the compiler to search 
    /usr/include/nvidia-current in order to get access to the CL/
    directory.  Link with -lOpenCl.
  \item Computers with ATI graphics cards and those which will can only
    run OpenCL on the processor (SSE2 required) will use the ATI
    Stream software.  This needs to be installed from a package on the
    ATI website: 
      \url{http://developer.amd.com/gpu/atistreamsdk/pages/default.aspx}
\end{enumerate}

\section{Host code}
Some example code (including perhaps old stuff from Apple) won't run
correctly on at least nVidia's OpenCL implementation.  Try to follow
this guide when setting up an OpenCL application.

\subsection{Context and kernel setup boilerplate}

\begin{minted}{c}
/* proper error handling omitted for brevity */
int err;

/* a lot of OpenCL calls follow this idiom: call a function with
  NULL arguments to learn how much space is required, then call again
  using that argument to retrieve data structures */
int num_platforms;
cl_platform_id *platforms = NULL;
err = clGetPlatformIDs(0, NULL, &num_platforms);
platforms = malloc(sizeof(*platforms) * num_platforms);
err = clGetPlatformIDs(num_platforms, platforms, NULL);

/* now you can page through the platforms IDs if you want.  most likely,
  you'll just want the first one if there even are multiple platforms
  available */

int num_devices;
cl_device_id *devices = NULL;
err = clGetDeviceIDs(platforms[0], 
    CL_DEVICE_TYPE_GPU | CL_DEVICE_TYPE_CPU, /* pick one */
    0,
    NULL,
    &num_devices);
devices = malloc(sizeof(*devices) * num_devices);
err = clGetDeviceIDs(platforms[0],
    CL_DEVICE_TYPE_GPU | CL_DEVICE_TYPE_CPU,
    num_devices,
    devices,
    NULL);

/* again, now you can page through the available devices if you want */

/* argument maps of sorts are passed around in OpenCL like this. */
cl_context_properties context_props[] = 
  { CL_CONTEXT_PLATFORM, platforms[0], 0 };
cl_context context;
context = clCreateContext(context_props, 
    1, /* num_devices */
    &devices[0], /* list of devices */
    NULL, /* asynchronous error notification function. pretty cool */
    &err);
/* non-null context implies success */

/* commands are issued to a device via a command queue. */
cl_command_queue commands;
commands = clCreateCommandQueue(context,
    devices[0], /* choose some device here; it must be associated with the
                  context passed as well */
    0, /* bitwise option field.  As of 1.0 your options are:
          CL_QUEUE_OUT_OF_ORDER_EXEC_MORE_ENABLE
          CL_QUEUE_PROFILING_ENABLE */
    &err);
/* non-zero/NULL command queue implies success */

/* now we go through the convoluted process of building the source.
  it's also possible to load a precompiled binary into OpenCL.  here, 
  we assume that the program source is either included in static memory
  or has been loaded into buffer char *source. */
cl_program program;
clCreateProgramWithSource(context,
  1, /* the number of char* in the following buffer */
  &source,
  NULL, /* implies all strings are NULL-terminated.  Same as 0 for an
      individual string. */
  &err);
/* non-zero program result implies success */
 
/* now we compile the thing.  we have the option of targeting the
  compile to a number of specific devices, or we can pass 0 and NULL
  to build for every device associated with the context (see above). 
  
  the options list is a string of options to pass to the compiler to
  define macros, add include directories and turn on or off optimizations.
  check the documentation: most of the optimizations are tradeoffs between
  correctness and speed. 
  
  the callback argument allows the program to be built asynchronously; 
  the clBuildProgram call won't block, and when compilation is complete,
  the callback will be called.  the callback function signature is
  void (*pfn_callback)(cl_program, void *user_data) */  
err = clBuildProgram(program, 
  0, /* num_devices */
  NULL, /* device list */
  NULL, /* options list */
  NULL, /* callback */
  NULL); /* user data for the callback */

/* there's not much to note here other than that "kernelName" is the name
  of one of the __kernel functions in the program compiler earlier */
cl_kernel kernel;
kernel = clCreateKernel(program, "kernelName", &err);
/* the Apple source I'm looking at suggests that one should check for
  both non-zero kernel and err == CL_SUCCESS to determine success */
\end{minted}

\subsection{Buffer management and kernel invocation}

\begin{minted}{c}
/* first, buffer creation: */
cl_mem buffer;
buffer = clCreateBuffer(context,
    flags, /* bitwise flags.  Here are the available values:
        CL_MEM_READ_WRITE - read and written by the kernel (default)
        CL_MEM_WRITE_ONLY - only written by kernel
        CL_MEM_READ_ONLY - read-only inside kernel
        CL_MEM_USE_HOST_PTR - if host_ptr is not null, use pointed-to memory
          when kernel executes
        CL_MEM_ALLOC_HOST_PTR - OpenCL should allocate memory accessible to
          host.  important: this memory can be "pinned" or "page locked", 
          resulting in increased performance in memory transfers between
          the CPU and GPU (pciE memory?).  obviously mutually exclusive with 
          CL_MEM_USE_HOST_PTR.
        CL_MEM_COPY_HOST_PTR - allocate own memory but copy from host_ptr.  if
          provided with ALLOC_HOST_PTR, then the resulting memory with be
          CPU accessible, too. */
    size, /* in bytes, like malloc */
    host_ptr,
    &err);
/* returns non-zero on success */

/* we also have functions to read, write and copy buffers */
cl_event event;
err = clEnqueueWriteBuffer(commands,
    buffer,
    CL_TRUE, /* blocking write? */
    0, /* offset */
    size, /* buffer write size */
    ptr, /* buffer to write _from_ */
    0, /* number of events to wait for before executing this write */
    NULL, /* list of events to wait for */
    &event); /* the event this write creates */

err = clEnqueueReadBuffer(commands,
    buffer,
    CL_TRUE, /* blocking read? */
    0, /* offset */
    size, /* size */
    0, /* number of events to wait for before executing this read */
    NULL, /* list of events */
    &event); /* event this read creates */

err = clEnqueueCopyBuffer(commands,
    src_buffer,
    dst_buffer,
    src_offset,
    dst_offset,
    size,
    0, /* number of events to wait for */
    NULL, /* list of events to wait for */
    &event); /* this operation's event */ 

err = clSetKernelArg(kernel,
    0, /* argument index */
    size, /* size of argument.  note: you're placing things on the "call 
      stack" here, so to speak.  so, the size of a buffer is 
      sizeof(cl_mem), not the size of the buffer's contents */
    &buffer); /* arg_value */

/* it's often helpful to query device-specific information when 
  deciding how to break up a workload. */
size_t work_group_size;
err = clGetKernelWorkGroupInfo(kernel,
    device, /* can be NULL if the kernel is associated with only one 
                device */
    param_name, /* which parameter to query.  the most interesting one
                  is CL_KERNEL_WORK_GROUP_SIZE */
    sizeof(size_t), /* param_value_size.  check the docs */
    &work_group_size, /* out */
    NULL); /* how many bytes of param buffer the function used */

/* finally, how to run a kernel! */
size_t sizes[] = { 16, 16, 256 };
size_t local_sizes = { 4, 4, 4 };
err = clEnqueueNDRangeKernel(commands, /* command queue */
    kernel,
    work_dim, /* dimension of work structure \in [1, 3] */
    NULL, /* reserved for change in a future version of OpenCL */
    sizes, /* dimension sizes */
    local_sizes, /* dimensions of work groups */    
    0, /* number of events to wait for */
    NULL, /* events to wait for */
    &event); /* event this call produces */

/* wait until all enqueued commands have finished */
err = clFinish(commands);
\end{minted}

\subsection{Reference counting}
Finally, OpenCL does some internal reference counting.  Hooks to the 
refcounting aparatus can be had by the following objects:

\begin{minted}{c}
cl[Release|Retain]MemObject
                  Program
                  Kernel
                  CommandQueue
                  Context
\end{minted}
When these objects are created, a retain is automatically performed on them.
The caller inherits this reference.

\section{Kernel programming}
\subsection{Address spaces}
OpenCL 

\end{document}

